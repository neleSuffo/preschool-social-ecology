{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67662012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def return_highest_frame_number(image_dir, video_name):\n",
    "    \"\"\"\n",
    "    Return the highest frame number from image filenames in the given directory that is a multiple of 30.\n",
    "    Assumes filenames are in the format: \"{video_name}_{frame_number}.jpg\"\n",
    "    \"\"\"\n",
    "    video_name = os.path.splitext(video_name)[0]\n",
    "    video_dir = os.path.join(image_dir, video_name)\n",
    "    if not os.path.exists(video_dir):\n",
    "        print(f\"Directory {video_dir} does not exist.\")\n",
    "        return -1\n",
    "    max_frame = -1\n",
    "    for root, _, files in os.walk(video_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\"):\n",
    "                parts = file.rsplit(\"_\", 1)\n",
    "                if len(parts) == 2 and parts[1].endswith(\".jpg\"):\n",
    "                    try:\n",
    "                        frame_num = int(parts[1].replace(\".jpg\", \"\"))\n",
    "                        if frame_num % 30 == 0 and frame_num > max_frame:\n",
    "                            max_frame = frame_num\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "    print(f\"Highest frame number: is {max_frame}\")\n",
    "    return max_frame\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import os\n",
    "\n",
    "DB_PATH = \"/home/nele_pauline_suffo/ProcessedData/quantex_annotations/annotations.db\"\n",
    "TARGET_CATEGORIES = (3, 4, 5, 6, 7, 8, 12)\n",
    "\n",
    "def load_annotations_from_db(video_name=None, image_id=None):\n",
    "    \"\"\"\n",
    "    Query the annotations table and return a list of annotation dicts.\n",
    "\n",
    "    - Always filters: outside = 0\n",
    "    - Applies object_interaction = 'Yes' only for category_id in TARGET_CATEGORIES.\n",
    "      For other category_ids, object_interaction is not checked.\n",
    "    - Optionally filters by video_name (resolves to video_id) and/or image_id.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Resolve video_name -> video_id if provided\n",
    "    video_id = None\n",
    "    if video_name is not None:\n",
    "        cursor.execute(\"SELECT id FROM videos WHERE file_name = ?\", (video_name,))\n",
    "        result = cursor.fetchone()\n",
    "        if result:\n",
    "            video_id = result[0]\n",
    "        else:\n",
    "            print(f\"Video name '{video_name}' not found in videos table.\")\n",
    "            conn.close()\n",
    "            return []\n",
    "\n",
    "    base_query = \"SELECT video_id, image_id, category_id, bbox FROM annotations\"\n",
    "    # Always require outside = 0\n",
    "    conditions = [\"outside = 0\"]\n",
    "    params = []\n",
    "\n",
    "    # keep rows where either:\n",
    "    #  - category_id NOT IN TARGET_CATEGORIES  (no object_interaction check)\n",
    "    #  OR\n",
    "    #  - category_id IN TARGET_CATEGORIES AND object_interaction = 'Yes'\n",
    "    cat_list_str = \", \".join(str(c) for c in TARGET_CATEGORIES)\n",
    "    conditions.append(\n",
    "        f\"(category_id NOT IN ({cat_list_str}) OR (category_id IN ({cat_list_str}) AND object_interaction = 'Yes'))\"\n",
    "    )\n",
    "\n",
    "    if video_id is not None:\n",
    "        conditions.append(\"video_id = ?\")\n",
    "        params.append(video_id)\n",
    "    if image_id is not None:\n",
    "        conditions.append(\"image_id = ?\")\n",
    "        params.append(image_id)\n",
    "\n",
    "    if conditions:\n",
    "        query = base_query + \" WHERE \" + \" AND \".join(conditions)\n",
    "    else:\n",
    "        query = base_query\n",
    "\n",
    "    cursor.execute(query, params)\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    # Convert rows to list of dicts\n",
    "    annotations = []\n",
    "    for row in rows:\n",
    "        video_id_val, image_id_val, category, bbox_json = row\n",
    "        # bbox might be JSON string (list) or comma-separated\n",
    "        try:\n",
    "            bbox = json.loads(bbox_json)\n",
    "        except Exception:\n",
    "            bbox = [float(x) for x in bbox_json.split(\",\")]\n",
    "        annotations.append({\n",
    "            'video_id': video_id_val,\n",
    "            'frame_number': image_id_val,\n",
    "            'category': category,\n",
    "            'bbox': bbox,\n",
    "        })\n",
    "    return annotations\n",
    "\n",
    "def plot_annotations(video_name, frame_number, annotations_table, image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Plot image and draw bounding boxes for person/face annotations (pixel-based coordinates).\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "\n",
    "    # Prepare paths\n",
    "    video_name = os.path.splitext(video_name)[0]\n",
    "    frame_number_padded = str(frame_number).zfill(6)\n",
    "    image_filename = f\"{video_name}_{frame_number_padded}.jpg\"\n",
    "    image_path = os.path.join(image_folder, video_name, image_filename)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"⚠️ Image not found: {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Open image\n",
    "    img = Image.open(image_path)\n",
    "    img_w, img_h = img.size\n",
    "\n",
    "    # Create figure with same aspect ratio as image\n",
    "    fig, ax = plt.subplots(1, figsize=(img_w / 100, img_h / 100), dpi=100)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for ann in annotations_table:\n",
    "        bbox = [float(x) for x in ann['bbox']]  # [x, y, w, h]\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Sanity check: clamp bbox within image boundaries\n",
    "        x = max(0, min(x, img_w - 1))\n",
    "        y = max(0, min(y, img_h - 1))\n",
    "        w = min(w, img_w - x)\n",
    "        h = min(h, img_h - y)\n",
    "\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y),\n",
    "            w, h,\n",
    "            linewidth=2,\n",
    "            edgecolor='r' if ann['category'] == 'person' else 'b',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(\n",
    "            x, y - 5,\n",
    "            str(ann['category']),\n",
    "            color='white',\n",
    "            fontsize=8,\n",
    "            backgroundcolor='black'\n",
    "        )\n",
    "\n",
    "    # Save output\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, image_filename)\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ Saved annotated image to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e2d6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest frame number: is 19050\n",
      "✅ Saved annotated image to /home/nele_pauline_suffo/ProcessedData/frame_validation/quantex_at_home_id262565_2022_05_26_03_019020.jpg\n"
     ]
    }
   ],
   "source": [
    "video_name = \"quantex_at_home_id262565_2022_05_26_03.mp4\"\n",
    "output_dir = \"/home/nele_pauline_suffo/ProcessedData/frame_validation\"\n",
    "image_dir = \"/home/nele_pauline_suffo/ProcessedData/quantex_videos_processed\"\n",
    "frame = return_highest_frame_number(image_dir, video_name)\n",
    "frame = 15300\n",
    "annotations = load_annotations_from_db(video_name, frame)\n",
    "plot_annotations(video_name, frame, annotations, image_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a7259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leuphana-ipe-py3.8 (3.8.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
